{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load the houseprices data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('houseprices.cvs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Reimplement your model from the previous checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = ['overallqual', 'grlivarea', 'garagecars', 'garagearea', 'totalbsmtsf', 'firstflrsf']\n",
    "cat_col = ['exterqual', 'kitchenqual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([df[num_col], df[cat_col], df['saleprice']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_col:\n",
    "    df2 = pd.concat([df2, pd.get_dummies(df[col], drop_first=True, prefix = col)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.log(df2['saleprice'])\n",
    "X = df2.drop(['saleprice', 'exterqual', 'kitchenqual'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrm = LinearRegression()\n",
    "lrm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared of the model in the training set is: 0.8003528283156789\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in the test set is: 0.8329179475267747\n",
      "Mean absolute error of the prediction is: 0.12340351327054319\n",
      "Mean squared error of the prediction is: 0.030593672673704088\n",
      "Root mean squared error of the prediction is: 0.17491047045189745\n",
      "Mean absolute percentage error of the prediction is: 1.0445968696594476\n"
     ]
    }
   ],
   "source": [
    "pred_train = lrm.predict(X_train)\n",
    "pred_test = lrm.predict(X_test)\n",
    "\n",
    "print(\"R-squared of the model in the training set is: {}\".format(lrm.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model in the test set is: {}\".format(lrm.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, pred_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, pred_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, pred_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - pred_test) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Try OLS, Lasso, Ridge, and ElasticNet regression using the same model specification. This time, you need to do k-fold cross-validation to choose the best hyperparameter values for your models. Which model is the best? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1) OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm2 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score with 2 folds for OLS: 0.7950\n",
      "Cross validation score with 3 folds for OLS: 0.7949\n",
      "Cross validation score with 4 folds for OLS: 0.7944\n",
      "Cross validation score with 5 folds for OLS: 0.7952\n",
      "Cross validation score with 6 folds for OLS: 0.7940\n",
      "Cross validation score with 7 folds for OLS: 0.7957\n",
      "Cross validation score with 8 folds for OLS: 0.7971\n",
      "Cross validation score with 9 folds for OLS: 0.7965\n",
      "Cross validation score with 10 folds for OLS: 0.7929\n",
      "Best cross validation score: 0.7929 with 8 folds\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(2,11):\n",
    "    print('Cross validation score with {0} folds for OLS: {1:.4f}'.format(i, cross_val_score(lrm2, X, Y, cv = i, scoring = 'r2').mean()))\n",
    "lrm2_best_nfolds = np.argmax([cross_val_score(lrm2, X, Y, cv = i, scoring = 'r2').mean() for i in np.arange(2,11)]) + 2\n",
    "print('Best cross validation score: {0:.4f} with {1} folds'.format(cross_val_score(lrm2, X, Y, cv = i, scoring = 'r2').mean(), lrm2_best_nfolds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared of the model in the training set is: 0.7962754912474016\n",
      "-----Test set statistics-----\n",
      "Mean absolute error of the prediction is: 0.12289336788755638\n",
      "Mean squared error of the prediction is: 0.03248438348612612\n",
      "Root mean squared error of the prediction is: 0.1802342461524061\n",
      "Mean absolute percentage error of the prediction is: 1.030242480331095\n"
     ]
    }
   ],
   "source": [
    "pred_OLS = cross_val_predict(lrm2, X, Y, cv = lrm2_best_nfolds)\n",
    "\n",
    "print(\"R-squared of the model in the training set is: {}\".format(metrics.r2_score(Y, pred_OLS)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "# print(\"R-squared of the model in the test set is: {}\".format(cross_validate()))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(Y, pred_OLS)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(Y, pred_OLS)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(Y, pred_OLS)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((Y - pred_OLS) / Y)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2) Lasso Regression\n",
    "For Lasso regression, I need to set two things:  a list of alphas for the model to pick, and how many folds to use.  I set the list of alphas as 10^i, where i ranges from -30 to 30 in steps of 2.  I find the optimal number of folds with a for loop similar to the one for OLS.  The R-squared value for Lasso regression does not increase after 3 folds, so 3 folds are used.  The optimal value for alpha is 0.0001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_lst = [10**int(a) for a in np.arange(-30, 30, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value is 0.8003293246312333 with 2 folds\n",
      "R-squared value is 0.8003293246312333 with 3 folds\n",
      "R-squared value is 0.8003293246312333 with 4 folds\n",
      "R-squared value is 0.8003293246312333 with 5 folds\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(2,6):\n",
    "    tmp = LassoCV(alphas = alpha_lst, cv = i)\n",
    "    tmp.fit(X_train, y_train)\n",
    "    print('R-squared value is {} with {} folds'.format(tmp.score(X_train, y_train), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The alpha value for Lasso is: 0.0001\n"
     ]
    }
   ],
   "source": [
    "lasso = LassoCV(alphas = alpha_lst, cv=3)\n",
    "lasso.fit(X_train, y_train)\n",
    "print('The alpha value for Lasso is: {}'.format(lasso.alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared of the model on the Lasso training set is: 0.8003293246312333\n",
      "-----Test set statistics-----\n",
      "R-squared of the model on the Lasso test set is: 0.8325503147419295\n",
      "Mean absolute error of the Lasso prediction is: 0.12348407821102601\n",
      "Mean squared error of the Lasso prediction is: 0.030660988324410974\n",
      "Root mean squared error of the Lasso prediction is: 0.17510279359396574\n",
      "Mean absolute percentage error of the Lasso prediction is: 1.0452117801384997\n"
     ]
    }
   ],
   "source": [
    "y_lasso_train = lasso.predict(X_train)\n",
    "y_lasso_test = lasso.predict(X_test)\n",
    "\n",
    "print(\"R-squared of the model on the Lasso training set is: {}\".format(lasso.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model on the Lasso test set is: {}\".format(lasso.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the Lasso prediction is: {}\".format(mean_absolute_error(y_test, y_lasso_test)))\n",
    "print(\"Mean squared error of the Lasso prediction is: {}\".format(mse(y_test, y_lasso_test)))\n",
    "print(\"Root mean squared error of the Lasso prediction is: {}\".format(rmse(y_test, y_lasso_test)))\n",
    "print(\"Mean absolute percentage error of the Lasso prediction is: {}\".format(np.mean(np.abs((y_test - y_lasso_test) / y_test)) * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3) Ridge Regression\n",
    "The same alpha values from section 3.2 are used to the test Ridge regression model, and number of folds range from 2 to 4.  All the folds had the same R-squared value, so I will be using the same number of folds as I used for Lasso regression.  The optimal alpha value is 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value is 0.8003191321739819 with 2 folds\n",
      "R-squared value is 0.8003191321739819 with 3 folds\n",
      "R-squared value is 0.8003191321739819 with 4 folds\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(2,5):\n",
    "    tmp = RidgeCV(alphas = alpha_lst, cv = i)\n",
    "    tmp.fit(X_train, y_train)\n",
    "    print('R-squared value is {} with {} folds'.format(tmp.score(X_train, y_train), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The alpha value for Ridge is: 1\n"
     ]
    }
   ],
   "source": [
    "ridge = RidgeCV(alphas=alpha_lst, cv = 3)\n",
    "ridge.fit(X_train, y_train)\n",
    "print('The alpha value for Ridge is: {}'.format(ridge.alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared of the model on the Ridge training set is: 0.8003191321739819\n",
      "-----Test set statistics-----\n",
      "R-squared of the model on the Ridge test set is: 0.8323754038836404\n",
      "Mean absolute error of the Ridge prediction is: 0.1235609326546338\n",
      "Mean squared error of the Ridge prediction is: 0.03069301549588971\n",
      "Root mean squared error of the Ridge prediction is: 0.1751942222103506\n",
      "Mean absolute percentage error of the Ridge prediction is: 1.0458381765585514\n"
     ]
    }
   ],
   "source": [
    "y_ridge_train = ridge.predict(X_train)\n",
    "y_ridge_test = ridge.predict(X_test)\n",
    "\n",
    "print(\"R-squared of the model on the Ridge training set is: {}\".format(ridge.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model on the Ridge test set is: {}\".format(ridge.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the Ridge prediction is: {}\".format(mean_absolute_error(y_test, y_ridge_test)))\n",
    "print(\"Mean squared error of the Ridge prediction is: {}\".format(mse(y_test, y_ridge_test)))\n",
    "print(\"Root mean squared error of the Ridge prediction is: {}\".format(rmse(y_test, y_ridge_test)))\n",
    "print(\"Mean absolute percentage error of the Ridge prediction is: {}\".format(np.mean(np.abs((y_test - y_ridge_test) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4) ElasticNet\n",
    "Since ElasticNet regression is a blend of Lasso and Ridge regression, it too has an alpha hyperparameter.  It has an additional hyperparameter called l1_ratio.  The documentation suggests using an array closer to one, such as [.1, .5, .7, .9, .95, .99, 1].  Again, the R-squared value for 2-4 folds is the same.  I will use 3 folds to be consistent with the other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value is 0.8003293246312333 with 2 folds\n",
      "R-squared value is 0.8003293246312333 with 3 folds\n",
      "R-squared value is 0.8003293246312333 with 4 folds\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(2,5):\n",
    "    tmp = ElasticNetCV(alphas = alpha_lst, l1_ratio=  [.1, .5, .7, .9, .95, .99, 1],cv = i)\n",
    "    tmp.fit(X_train, y_train)\n",
    "    print('R-squared value is {} with {} folds'.format(tmp.score(X_train, y_train), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The alpha value and l1_ratio for ElasticNet are 0.0001 and 1.0\n"
     ]
    }
   ],
   "source": [
    "elastic = ElasticNetCV(alphas= alpha_lst, l1_ratio= [.1, .5, .7, .9, .95, .99, 1], cv = 3)\n",
    "elastic.fit(X_train, y_train)\n",
    "print('The alpha value and l1_ratio for ElasticNet are {} and {}'.format(elastic.alpha_, elastic.l1_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared of the model on the ElasticNet training set is: 0.8003293246312333\n",
      "-----Test set statistics-----\n",
      "R-squared of the model on the ElasticNet test set is: 0.8325503147419295\n",
      "Mean absolute error of the ElasticNet prediction is: 0.12348407821102601\n",
      "Mean squared error of the ElasticNet prediction is: 0.030660988324410974\n",
      "Root mean squared error of the ElasticNet prediction is: 0.17510279359396574\n",
      "Mean absolute percentage error of the ElasticNet prediction is: 1.0452117801384997\n"
     ]
    }
   ],
   "source": [
    "y_elastic_train = elastic.predict(X_train)\n",
    "y_elastic_test = elastic.predict(X_test)\n",
    "\n",
    "print(\"R-squared of the model on the ElasticNet training set is: {}\".format(elastic.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model on the ElasticNet test set is: {}\".format(elastic.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the ElasticNet prediction is: {}\".format(mean_absolute_error(y_test, y_elastic_test)))\n",
    "print(\"Mean squared error of the ElasticNet prediction is: {}\".format(mse(y_test, y_elastic_test)))\n",
    "print(\"Root mean squared error of the ElasticNet prediction is: {}\".format(rmse(y_test, y_elastic_test)))\n",
    "print(\"Mean absolute percentage error of the ElasticNet prediction is: {}\".format(np.mean(np.abs((y_test - y_elastic_test) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5) Which model is the best?\n",
    "A table below summarizes the R-squared value for training and test sets, the MAE, MSE, RMSE, and MAPE for all four models.  OLS had the lowest R-squared values, but its error metrics were mixed.  Overall, the Lasso, Ridge, and ElasticNet regressions had similar reults.  In fact, the l1 ratio for the ElasticNet regression was 1, which means it is a Lasso regression.  Ridge regression has the lower R-squared value for the test set, but generally has higher error metrics.  It is difficult to pick if Ridge or Lasso regression is better in this case.  \n",
    "\n",
    "Generally, I don't think results between each model should be this close together.  My guess is that my work in the feature engineering phase was not optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | R-squared Training Set  | R-squared Test Set  | MAE  | MSE  | RMSE  | MAPE  |\n",
    "|------|------|\n",
    "|   OLS  | 0.7963| NA  | 0.1229  | 0.0325  | 0.1802  | 1.030 |\n",
    "|   Lasso  |   0.8003  |   0.8326  |   0.1235  |   0.0307  |   0.1751  |   1.045  |\n",
    "|   Ridge  |   0.8003  |   0.8324  |   0.1236  |   0.0307  |   0.1752  |   1.046  |\n",
    "|   ElasticNet  |   0.8003  |   0.8326  |   0.1235  |   0.0307  |   0.1751  |   1.045|  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
